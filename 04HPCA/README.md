# High-Performance Computer Architecture

## Journal

*IEEE Transactions on Emerging Topics in Computing (TETC)*<br>

## Conference

*International Symposium on Microarchitecture (MICRO)*<br>

*International Symposium on Computer Architecture (ISCA)*<br>

*International Conference on Software Engineering (ICSE)*<br>

*Architectural Support for Programming Languages and Operating Systems (ASPLOS)*<br>

*International Symposium on High-Performance Computer Architecture (HPCA)*<br>

*International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)*<br>

## Busniess

**寒武纪**<br>
[[Homepage](http://cambricon.com/)]

## Group

**Yunji Chen**<br>
*Institute of Computing Technology, Chinese Academy of Sciences*<br>
[[Homepage](http://novel.ict.ac.cn/ychen/)]
[[Google Scholar](https://scholar.google.com.hk/citations?user=fXeoWugAAAAJ&hl=zh-CN&oi=ao)]

## Resource

**AI-Chip**<br>
[[Github](https://github.com/basicmi/AI-Chip)]

**Neural Networks on Silicon**<br>
[[Github](https://github.com/fengbintu/Neural-Networks-on-Silicon)]

## Heterogeneous Computing

**Heterogeneous integration for on-chip quantum photonic circuits with single quantum dot devices.**<br>
*M Davanco, J Liu, L Sapienza, CZ Zhang, et al.*<br>
Nature Communications, 2017.

**Distributed Deep Learning With GPU-FPGA Heterogeneous Computing.**<br>
*K Tanaka, Y Arikawa, T Ito, K Morita, N Nemoto, et al.*<br>
IEEE Micro, 2020.

**Heterogeneous dataflow accelerators for multi-DNN workloads.**<br>
*H Kwon, L Lai, M Pellauer, T Krishna, et al.*<br>
HPCA, 2021.

## Machine Learning Accelerator

### Review

**Benchmarking tpu, gpu, and cpu platforms for deep learning.**<br>
*YE Wang, GY Wei, D Brooks.*<br>
ArXiv, 2019.

**A survey of accelerator architectures for deep neural networks.**<br>
*Y Chen, Y Xie, L Song, F Chen, T Tang.*<br>
Engineering, 2020.

**An updated survey of efficient hardware architectures for accelerating deep convolutional neural networks.**<br>
*M Capra, B Bussolino, A Marchisio, M Shafique, et al.*<br>
Future Internet, 2020.

**Survey of machine learning accelerators.**<br>
*A Reuther, P Michaleas, M Jones, V Gadepally, S Samsi, J Kepner.*<br>
HPEC, 2020.

**Fair and comprehensive benchmarking of machine learning processing chips.**<br>
*GW Burr, SH Lim, B Murmann, R Venkatesan, et al.*<br>
IEEE Design & Test, 2021.

**AI Accelerator Survey and Trends.**<br>
*A Reuther, P Michaleas, M Jones, V Gadepally, S Samsi, J Kepner.*<br>
HPEC, 2021.

### CPU

**Slide: In defense of smart algorithms over hardware acceleration for large-scale deep learning systems.**<br>
*B Chen, T Medini, J Farwell, C Tai, et al.*<br>
MLSys, 2020.

### GPU

**cudnn: Efficient primitives for deep learning.**<br>
*S Chetlur, C Woolley, P Vandermersch, et al.*<br>
ArXiv, 2014.

**Deepmon: Mobile gpu-based deep learning framework for continuous vision applications.**<br>
*LN Huynh, Y Lee, RK Balan.*<br>
MobiSys, 2017.

### TPU

**In-datacenter performance analysis of a tensor processing unit.**<br>
*NP Jouppi, C Young, N Patil, D Patterson, et al.*<br>
ISCA, 2017.

### ASIC
**Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning.**<br>
*T Chen, Z Du, N Sun, J Wang, C Wu, Y Chen, et al.*<br>
ASPLOS, 2014.

### FPGA

**Optimizing fpga-based accelerator design for deep convolutional neural networks.**<br>
*C Zhang, P Li, G Sun, Y Guan, B Xiao, et al.*<br>
FPGA, 2015.




